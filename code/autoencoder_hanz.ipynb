{"metadata": {"colab": {"name": "autoencoder.ipynb", "provenance": [], "collapsed_sections": []}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "! pip install tensorflow", "metadata": {"trusted": true}, "execution_count": 7, "outputs": [{"name": "stdout", "text": "\u001b[33mWARNING: The directory '/home/dnanexus/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.6/site-packages (2.6.2)\nRequirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.19.5)\nRequirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.19.3)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.15.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.12)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\nRequirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.43.0)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: tensorboard<2.7,>=2.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (5.0)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.23.0)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (58.0.4)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.25.11)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "# download model input data from DNANexus folder\n#%%bash\n!dx download \"model_input\" -r", "metadata": {"trusted": true}, "execution_count": 8, "outputs": [{"name": "stdout", "text": "\u001b[2K[===========================================================>] Completed 4,543 of 4,543 bytes (100%) /opt/notebooks/model_input/README.mdd\n\u001b[2K[===========================================================>] Completed 3,051,744 of 3,051,744 bytes (100%) /opt/notebooks/model_input/Indel_VCFs.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 1,588,467 of 1,588,467 bytes (100%) /opt/notebooks/model_input/SNP_VCFs.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 228,801 of 228,801 bytes (100%) /opt/notebooks/model_input/SNP_VCFs.cS2G_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 6,472,066 of 6,472,066 bytes (100%) /opt/notebooks/model_input/Indel_VCFs.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 638 of 638 bytes (100%) /opt/notebooks/model_input/pheno_data.tsvv\n\u001b[2K[===========================================================>] Completed 317,021 of 317,021 bytes (100%) /opt/notebooks/model_input/SV_VCFs.INS.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 293,991 of 293,991 bytes (100%) /opt/notebooks/model_input/SV_VCFs.DEL.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 628 of 628 bytes (100%) /opt/notebooks/model_input/SV_VCFs.INV.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 610 of 610 bytes (100%) /opt/notebooks/model_input/SV_VCFs.DUP-TANDEM.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 320,514 of 320,514 bytes (100%) /opt/notebooks/model_input/SNP_VCFs.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 175,388 of 175,388 bytes (100%) /opt/notebooks/model_input/SV_VCFs.DEL.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 55,182 of 55,182 bytes (100%) /opt/notebooks/model_input/SV_VCFs.INS.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 630 of 630 bytes (100%) /opt/notebooks/model_input/SV_VCFs.DUP-TANDEM.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 1,114 of 1,114 bytes (100%) /opt/notebooks/model_input/SV_VCFs.INV.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 2,484 of 2,484 bytes (100%) /opt/notebooks/model_input/HERV_K_Insertions.txtt\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "import tensorflow as tf\nimport keras\nfrom keras import layers\nfrom keras.layers import Input, Dense\nfrom tensorflow.keras import regularizers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd", "metadata": {"trusted": true}, "execution_count": 32, "outputs": []}, {"cell_type": "markdown", "source": "# Load and preprocess data", "metadata": {}}, {"cell_type": "code", "source": "insertions_data = pd.read_csv('model_input/HERV_K_Insertions.txt',sep='\\t',index_col=0)", "metadata": {"trusted": true}, "execution_count": 11, "outputs": []}, {"cell_type": "code", "source": "input1 = insertions_data.values\nX = [input1]\ninput_shape = input1.shape[-1]", "metadata": {"trusted": true}, "execution_count": 83, "outputs": []}, {"cell_type": "code", "source": "for i, ii in enumerate(insertions_data):\n    print(ii)", "metadata": {"trusted": true}, "execution_count": 89, "outputs": [{"name": "stdout", "text": "chr1:111802591-111802598\nchr1:223578303-223578310\nchr4:9603239-9603245\nchr4:9981605-9981606\nchr4:190966833-190966919\nchr5:4537604-4537605\nchr5:64388439-64388446\nchr5:80442265-80442272\nchr6:16004793-16004926\nchr6:32643383-32643537\nchr6:32648035-32648041\nchr6:161270898-161270905\nchr7:158773312-158773459\nchr8:146086169-146086170\nchr9:132205208-132205208\nchr10:101016044-101016228\nchr10:134444012-134444013\nchr11:60449889-60449889\nchr12:44313656-44313662\nchr12:124066476-124066483\nchr13:90743182-90743189\nchr15:28430044-28430186\nchr15:63374593-63374600\nchr19:21841536-21841542\nchr19:22414303-22414381\nchr19:22457244-22457245\nchr19:29855781-29855787\nchr19:57996939-57996940\nchr20:12402386-12402392\nchr22:23852639-23852640\nchrX:93606603-93606604\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "# Model", "metadata": {}}, {"cell_type": "code", "source": "#AUTOENCODER MODEL DEFINITION\n# This is the size of our encoded representations\nencoding_dim = 5 \n\n# This is our input image\ninput_layer = keras.Input(shape=input_shape,name='input')\n\n# \"encoded\" is the encoded representation of the input, we can add strong regularization here if n_samples << n_features\nencoded = layers.Dense(encoding_dim, activation='relu',name='compressed_representation')(input_layer)\n\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = layers.Dense(input_shape, activation='sigmoid',name='reconstructed_output')(encoded)\n\n# This model maps an input to its reconstruction\nautoencoder = keras.Model(input_layer, decoded)", "metadata": {"id": "vYghjfhrj1Fg", "trusted": true}, "execution_count": 45, "outputs": []}, {"cell_type": "code", "source": "tf.keras.utils.plot_model(autoencoder, \"multi_input_and_output_model.png\", show_shapes=True)\n", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 312}, "id": "XjnYTsoRlkjm", "outputId": "5e793908-fb81-4ed2-ddc0-eccfdb98a757", "trusted": true}, "execution_count": 46, "outputs": [{"name": "stdout", "text": "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "# Training", "metadata": {}}, {"cell_type": "code", "source": "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n", "metadata": {"id": "v8k-KhCXkNYB", "trusted": true}, "execution_count": 47, "outputs": []}, {"cell_type": "code", "source": "hisotry = autoencoder.fit(X,X,\n                epochs=50,\n                batch_size=5,\n                shuffle=True,\n                validation_split=0.2,verbose=2)", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "JnNPDpxclY5R", "outputId": "49404b33-d9bc-4425-cb8e-8c8ca472ad79", "trusted": true}, "execution_count": 48, "outputs": [{"name": "stdout", "text": "Epoch 1/50\n4/4 - 0s - loss: 0.6688 - val_loss: 0.6643\nEpoch 2/50\n4/4 - 0s - loss: 0.6654 - val_loss: 0.6604\nEpoch 3/50\n4/4 - 0s - loss: 0.6620 - val_loss: 0.6567\nEpoch 4/50\n4/4 - 0s - loss: 0.6589 - val_loss: 0.6530\nEpoch 5/50\n4/4 - 0s - loss: 0.6556 - val_loss: 0.6493\nEpoch 6/50\n4/4 - 0s - loss: 0.6522 - val_loss: 0.6455\nEpoch 7/50\n4/4 - 0s - loss: 0.6486 - val_loss: 0.6414\nEpoch 8/50\n4/4 - 0s - loss: 0.6452 - val_loss: 0.6372\nEpoch 9/50\n4/4 - 0s - loss: 0.6414 - val_loss: 0.6330\nEpoch 10/50\n4/4 - 0s - loss: 0.6374 - val_loss: 0.6285\nEpoch 11/50\n4/4 - 0s - loss: 0.6335 - val_loss: 0.6241\nEpoch 12/50\n4/4 - 0s - loss: 0.6293 - val_loss: 0.6197\nEpoch 13/50\n4/4 - 0s - loss: 0.6250 - val_loss: 0.6152\nEpoch 14/50\n4/4 - 0s - loss: 0.6207 - val_loss: 0.6106\nEpoch 15/50\n4/4 - 0s - loss: 0.6164 - val_loss: 0.6059\nEpoch 16/50\n4/4 - 0s - loss: 0.6116 - val_loss: 0.6012\nEpoch 17/50\n4/4 - 0s - loss: 0.6071 - val_loss: 0.5964\nEpoch 18/50\n4/4 - 0s - loss: 0.6024 - val_loss: 0.5913\nEpoch 19/50\n4/4 - 0s - loss: 0.5976 - val_loss: 0.5861\nEpoch 20/50\n4/4 - 0s - loss: 0.5926 - val_loss: 0.5808\nEpoch 21/50\n4/4 - 0s - loss: 0.5876 - val_loss: 0.5753\nEpoch 22/50\n4/4 - 0s - loss: 0.5826 - val_loss: 0.5699\nEpoch 23/50\n4/4 - 0s - loss: 0.5774 - val_loss: 0.5640\nEpoch 24/50\n4/4 - 0s - loss: 0.5723 - val_loss: 0.5579\nEpoch 25/50\n4/4 - 0s - loss: 0.5668 - val_loss: 0.5521\nEpoch 26/50\n4/4 - 0s - loss: 0.5619 - val_loss: 0.5462\nEpoch 27/50\n4/4 - 0s - loss: 0.5566 - val_loss: 0.5404\nEpoch 28/50\n4/4 - 0s - loss: 0.5516 - val_loss: 0.5346\nEpoch 29/50\n4/4 - 0s - loss: 0.5466 - val_loss: 0.5289\nEpoch 30/50\n4/4 - 0s - loss: 0.5419 - val_loss: 0.5233\nEpoch 31/50\n4/4 - 0s - loss: 0.5370 - val_loss: 0.5177\nEpoch 32/50\n4/4 - 0s - loss: 0.5327 - val_loss: 0.5119\nEpoch 33/50\n4/4 - 0s - loss: 0.5277 - val_loss: 0.5065\nEpoch 34/50\n4/4 - 0s - loss: 0.5232 - val_loss: 0.5013\nEpoch 35/50\n4/4 - 0s - loss: 0.5191 - val_loss: 0.4959\nEpoch 36/50\n4/4 - 0s - loss: 0.5144 - val_loss: 0.4909\nEpoch 37/50\n4/4 - 0s - loss: 0.5100 - val_loss: 0.4855\nEpoch 38/50\n4/4 - 0s - loss: 0.5060 - val_loss: 0.4801\nEpoch 39/50\n4/4 - 0s - loss: 0.5016 - val_loss: 0.4751\nEpoch 40/50\n4/4 - 0s - loss: 0.4976 - val_loss: 0.4702\nEpoch 41/50\n4/4 - 0s - loss: 0.4937 - val_loss: 0.4653\nEpoch 42/50\n4/4 - 0s - loss: 0.4900 - val_loss: 0.4607\nEpoch 43/50\n4/4 - 0s - loss: 0.4864 - val_loss: 0.4565\nEpoch 44/50\n4/4 - 0s - loss: 0.4831 - val_loss: 0.4526\nEpoch 45/50\n4/4 - 0s - loss: 0.4798 - val_loss: 0.4485\nEpoch 46/50\n4/4 - 0s - loss: 0.4768 - val_loss: 0.4445\nEpoch 47/50\n4/4 - 0s - loss: 0.4736 - val_loss: 0.4406\nEpoch 48/50\n4/4 - 0s - loss: 0.4708 - val_loss: 0.4367\nEpoch 49/50\n4/4 - 0s - loss: 0.4680 - val_loss: 0.4330\nEpoch 50/50\n4/4 - 0s - loss: 0.4654 - val_loss: 0.4294\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "# Use encoder to reduce dimensions", "metadata": {}}, {"cell_type": "code", "source": "# encoder part, to compress data with after training\nencoder = keras.Model(input_layer, encoded)\nencoded_input = Input(shape = (encoding_dim, ))", "metadata": {"id": "Vdum-xZBl9IJ", "trusted": true}, "execution_count": 49, "outputs": []}, {"cell_type": "code", "source": "encoded_train = pd.DataFrame(encoder.predict(X))\nencoded_train = encoded_train.add_prefix('feature_')", "metadata": {"trusted": true}, "execution_count": 50, "outputs": []}, {"cell_type": "code", "source": "print(encoded_train.shape)\nencoded_train", "metadata": {"trusted": true}, "execution_count": 51, "outputs": [{"name": "stdout", "text": "(20, 5)\n", "output_type": "stream"}, {"execution_count": 51, "output_type": "execute_result", "data": {"text/plain": "    feature_0  feature_1  feature_2  feature_3  feature_4\n0    1.145717   1.592631   0.744760        0.0   1.348833\n1    1.886658   2.728269   2.078684        0.0   2.333317\n2    2.492687   3.053942   1.878806        0.0   1.812229\n3    3.676575   3.771553   1.042752        0.0   0.398188\n4    2.469799   2.894288   0.391026        0.0   0.469780\n5    2.126485   1.761699   0.000000        0.0   0.243871\n6    2.509242   1.820783   1.366839        0.0   0.969464\n7    2.400369   2.199226   0.490438        0.0   0.381688\n8    1.410719   1.648086   0.393364        0.0   0.665049\n9    1.454444   2.553384   1.209379        0.0   1.378522\n10   1.028895   1.595546   2.933871        0.0   1.680922\n11   1.145781   2.051228   1.825159        0.0   1.099941\n12   1.540725   2.667563   2.267836        0.0   1.899101\n13   1.447641   1.281364   1.991559        0.0   0.781300\n14   1.222427   2.006528   1.684774        0.0   1.888766\n15   2.442249   3.167550   1.269403        0.0   1.243031\n16   1.715304   2.311748   1.233527        0.0   0.918834\n17   2.324343   2.477278   1.989902        0.0   1.300508\n18   2.025533   2.143196   1.668835        0.0   1.273180\n19   0.752750   2.105245   0.170039        0.0   1.526309", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_0</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.145717</td>\n      <td>1.592631</td>\n      <td>0.744760</td>\n      <td>0.0</td>\n      <td>1.348833</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.886658</td>\n      <td>2.728269</td>\n      <td>2.078684</td>\n      <td>0.0</td>\n      <td>2.333317</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.492687</td>\n      <td>3.053942</td>\n      <td>1.878806</td>\n      <td>0.0</td>\n      <td>1.812229</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.676575</td>\n      <td>3.771553</td>\n      <td>1.042752</td>\n      <td>0.0</td>\n      <td>0.398188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.469799</td>\n      <td>2.894288</td>\n      <td>0.391026</td>\n      <td>0.0</td>\n      <td>0.469780</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.126485</td>\n      <td>1.761699</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.243871</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2.509242</td>\n      <td>1.820783</td>\n      <td>1.366839</td>\n      <td>0.0</td>\n      <td>0.969464</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.400369</td>\n      <td>2.199226</td>\n      <td>0.490438</td>\n      <td>0.0</td>\n      <td>0.381688</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.410719</td>\n      <td>1.648086</td>\n      <td>0.393364</td>\n      <td>0.0</td>\n      <td>0.665049</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.454444</td>\n      <td>2.553384</td>\n      <td>1.209379</td>\n      <td>0.0</td>\n      <td>1.378522</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.028895</td>\n      <td>1.595546</td>\n      <td>2.933871</td>\n      <td>0.0</td>\n      <td>1.680922</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.145781</td>\n      <td>2.051228</td>\n      <td>1.825159</td>\n      <td>0.0</td>\n      <td>1.099941</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.540725</td>\n      <td>2.667563</td>\n      <td>2.267836</td>\n      <td>0.0</td>\n      <td>1.899101</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.447641</td>\n      <td>1.281364</td>\n      <td>1.991559</td>\n      <td>0.0</td>\n      <td>0.781300</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.222427</td>\n      <td>2.006528</td>\n      <td>1.684774</td>\n      <td>0.0</td>\n      <td>1.888766</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2.442249</td>\n      <td>3.167550</td>\n      <td>1.269403</td>\n      <td>0.0</td>\n      <td>1.243031</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1.715304</td>\n      <td>2.311748</td>\n      <td>1.233527</td>\n      <td>0.0</td>\n      <td>0.918834</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2.324343</td>\n      <td>2.477278</td>\n      <td>1.989902</td>\n      <td>0.0</td>\n      <td>1.300508</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2.025533</td>\n      <td>2.143196</td>\n      <td>1.668835</td>\n      <td>0.0</td>\n      <td>1.273180</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.752750</td>\n      <td>2.105245</td>\n      <td>0.170039</td>\n      <td>0.0</td>\n      <td>1.526309</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "# Node ranking", "metadata": {}}, {"cell_type": "code", "source": "compressed_w = autoencoder.get_layer('compressed_representation').get_weights()[0].flatten()", "metadata": {"trusted": true}, "execution_count": 59, "outputs": []}, {"cell_type": "code", "source": "%pylab inline\nhist(compressed_w);", "metadata": {"trusted": true}, "execution_count": 60, "outputs": [{"name": "stdout", "text": "Populating the interactive namespace from numpy and matplotlib\n", "output_type": "stream"}, {"output_type": "display_data", "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}, "metadata": {"needs_background": "light"}}]}, {"cell_type": "code", "source": "mod_w = autoencoder.get_layer('reconstructed_output').get_weights()[0].flatten()\ntot_w = compressed_w*mod_w[0]\nmod_order = tot_w.argsort()[::-1] # to rank from larger to smaller\nmod_ranks = mod_order.argsort()\n\ndf = pd.DataFrame(columns=['Rank','Score'])\ndf['Rank'] = mod_ranks\ndf['Score'] = tot_w\noutput_dfs = df.sort_values(by=['Rank'])", "metadata": {"trusted": true}, "execution_count": 75, "outputs": []}, {"cell_type": "code", "source": "print(output_dfs)", "metadata": {"trusted": true}, "execution_count": 76, "outputs": [{"name": "stdout", "text": "     Rank     Score\n107     0  0.164591\n105     1  0.160969\n109     2  0.158162\n106     3  0.156264\n130     4  0.151363\n..    ...       ...\n33    150 -0.105190\n22    151 -0.108153\n153   152 -0.109463\n67    153 -0.124753\n119   154 -0.130206\n\n[155 rows x 2 columns]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "encoded.shape", "metadata": {"trusted": true}, "execution_count": 79, "outputs": [{"execution_count": 79, "output_type": "execute_result", "data": {"text/plain": "TensorShape([None, 5])"}, "metadata": {}}]}, {"cell_type": "code", "source": "decoded.shape", "metadata": {"trusted": true}, "execution_count": 80, "outputs": [{"execution_count": 80, "output_type": "execute_result", "data": {"text/plain": "TensorShape([None, 31])"}, "metadata": {}}]}, {"cell_type": "code", "source": "for i, i_name in enumerate(insertions_data):\n    features_w = autoencoder.get_layer('compressed_representation').get_weights()[0].flatten()\n    tot_w = mod_w[i]*features_w\n    mod_order = tot_w.argsort()[::-1] # to rank from larger to smaller\n    mod_ranks = mod_order.argsort()\n\n#     df = pd.DataFrame(columns=['Feature_ID','Rank','Score'])\n#     df['Feature_ID'] = genes\n#     df['Rank'] = mod_ranks\n#     df['Score'] = tot_w", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "# Insertion ranking", "metadata": {}}, {"cell_type": "code", "source": "dataframes = {}\ninsertion = insertions_data.keys()\n\nmod_w = autoencoder.get_layer('reconstructed_output').get_weights()[1].flatten()\n\nmod_df = pd.DataFrame(columns=['Insertion','Weight'])\nmod_df['Insertion'] = insertion\nmod_df['Weight'] = mod_w", "metadata": {"trusted": true}, "execution_count": 184, "outputs": []}, {"cell_type": "code", "source": "from pathlib import Path\noutput_path = 'dimensionality_reduction'\n\n# make dir\nPath(output_path).mkdir(parents=True, exist_ok=True)\n\n# save insertion weigths\nmod_df.to_csv(output_path +'/insertion_weights',sep='\\t',index=False,header=mod_df.columns)", "metadata": {"trusted": true}, "execution_count": 196, "outputs": []}, {"cell_type": "code", "source": "# upload output to DNAnexus\n!dx upload -r dimensionality_reduction", "metadata": {"trusted": true}, "execution_count": 197, "outputs": [{"name": "stdout", "text": "[===========================================================>] Uploaded 1,127 of 1,127 bytes (100%) dimensionality_reduction/insertion_weights\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}