{"metadata": {"colab": {"name": "multimodal_classifier.ipynb", "provenance": [], "collapsed_sections": []}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "! pip install tensorflow\n! pip install sklearn", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "trusted": true}, "execution_count": 50, "outputs": [{"name": "stdout", "text": "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.6/site-packages (2.6.2)\nRequirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.43.0)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.19.5)\nRequirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (5.0)\nRequirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.12)\nRequirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.15.0)\nRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.19.3)\nRequirement already satisfied: tensorboard<2.7,>=2.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.23.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (58.0.4)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.25.11)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n\u001b[31mERROR: Could not find a version that satisfies the requirement scikitlearn (from versions: none)\u001b[0m\n\u001b[31mERROR: No matching distribution found for scikitlearn\u001b[0m\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "! pip install sklearn", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "trusted": true}, "execution_count": 52, "outputs": [{"name": "stdout", "text": "Collecting sklearn\n  Downloading sklearn-0.0.tar.gz (1.1 kB)\nCollecting scikit-learn\n  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22.2 MB 39.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.5.4)\nCollecting joblib>=0.11\n  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 306 kB 114.8 MB/s eta 0:00:01\n\u001b[?25hCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.19.5)\nBuilding wheels for collected packages: sklearn\n  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=69a830ff0431c2f9ad21124316ac12048afce59ff89c8a0677134daae6577359\n  Stored in directory: /home/dnanexus/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\nSuccessfully built sklearn\nInstalling collected packages: threadpoolctl, joblib, scikit-learn, sklearn\nSuccessfully installed joblib-1.1.0 scikit-learn-0.24.2 sklearn-0.0 threadpoolctl-3.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "# download model input data from DNANexus folder\n#%%bash\n!dx download \"model_input\" -r", "metadata": {"trusted": true}, "execution_count": 26, "outputs": [{"name": "stdout", "text": "\u001b[2K[===========================================================>] Completed 2,291 of 2,291 bytes (100%) /opt/notebooks/model_input/README.mdd\n\u001b[2K[===========================================================>] Completed 638 of 638 bytes (100%) /opt/notebooks/model_input/pheno_data.tsvv\n\u001b[2K[===========================================================>] Completed 317,021 of 317,021 bytes (100%) /opt/notebooks/model_input/SV_VCFs.INS.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 293,991 of 293,991 bytes (100%) /opt/notebooks/model_input/SV_VCFs.DEL.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 628 of 628 bytes (100%) /opt/notebooks/model_input/SV_VCFs.INV.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 610 of 610 bytes (100%) /opt/notebooks/model_input/SV_VCFs.DUP-TANDEM.gene_scores_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 320,514 of 320,514 bytes (100%) /opt/notebooks/model_input/SNP_VCFs.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 175,388 of 175,388 bytes (100%) /opt/notebooks/model_input/SV_VCFs.DEL.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 55,182 of 55,182 bytes (100%) /opt/notebooks/model_input/SV_VCFs.INS.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 630 of 630 bytes (100%) /opt/notebooks/model_input/SV_VCFs.DUP-TANDEM.genotype_matrix.tsv.gzz\n\u001b[2K[===========================================================>] Completed 1,114 of 1,114 bytes (100%) /opt/notebooks/model_input/SV_VCFs.INV.genotype_matrix.tsv.gzz\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/dxpy/cli/download.py\", line 180, in _download_folders\n    show_progress=show_progress)\n  File \"/opt/conda/lib/python3.6/site-packages/dxpy/bindings/dxfile_functions.py\", line 722, in download_folder\n    \"Destination file '{}' already exists but no overwrite option is provided\".format(local_filename)\ndxpy.exceptions.DXFileError: Destination file '/opt/notebooks/model_input/HERV_K_Insertions.txt' already exists but no overwrite option is provided\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "import tensorflow as tf\nimport keras\nfrom keras import layers\nfrom tensorflow.keras import regularizers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pathlib import Path\nfrom os import listdir\nimport pickle\nfrom sklearn.preprocessing import StandardScaler", "metadata": {"id": "m9qO96uJaINb", "trusted": true}, "execution_count": 53, "outputs": []}, {"cell_type": "code", "source": "%clear", "metadata": {"trusted": true}, "execution_count": 39, "outputs": [{"name": "stdout", "text": "\u001b[H\u001b[2J", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "# PARAMETERS", "metadata": {}}, {"cell_type": "code", "source": "# analysis parameters\nsurvival_th = 2 #threshold betw. low and high survival\n# PATHS and files\ninput_path = 'model_input'\noutput_path = 'model_output'\n\nignore_files = ['README.md'] # files that are not feature input data\nlabel_file = 'pheno_data.tsv' # name of the label file\n\n# model_parameters\nL1_REGULARIZATION = 0.5 #l1 regularization parameter\nEPOCHS = 100    #number of training epochs\nVALIDATION_SPLIT = 0.1    #fraction of data held out for validation\nBATCH_SIZE = 1    # size of training batches\n", "metadata": {"trusted": true}, "execution_count": 54, "outputs": []}, {"cell_type": "markdown", "source": "# Load and preprocess data", "metadata": {}}, {"cell_type": "code", "source": "def fill_nans(df):\n    #frist substitute nans with coulumns mean, that does not affect performance\n    filled_df = df.fillna(df.mean())\n    #for all nan columns, put zeros as constant value\n    filled_df = filled_df.fillna(0)\n    return filled_df\n", "metadata": {"trusted": true}, "execution_count": 55, "outputs": []}, {"cell_type": "code", "source": "#load all feature files and clean them\nfile_names = [f for f in listdir(input_path)]\ndataframes = {}\nfor fname in file_names:\n    if not (fname in ignore_files or fname==label_file):\n        df = pd.read_csv(input_path+'/'+fname,sep='\\t',index_col=0)\n        df = fill_nans(df)\n        dataframes[fname] = df\n\nmodalities = dataframes.keys()\n# load phenotipes for label construction\nlabels_df = pd.read_csv(input_path+'/'+label_file,sep='\\t',index_col=0)\n\n# to add checks that all IDS are in the same order in all dataframes", "metadata": {"trusted": true}, "execution_count": 56, "outputs": []}, {"cell_type": "code", "source": "# prepares input matrices\nX0 = [x.values for x in dataframes.values()]\n# z-score inputs in each modality\nscaler = StandardScaler()\nX = [scaler.fit_transform(x) for x in X0]\n# prepare labels for bynary classification, low survival=1, high survival=0 \nY = np.array([1 if y<survival_th else 0 for y in labels_df['Phe3_Surv_years'].values])", "metadata": {"id": "PBVyTC0lZG29", "trusted": true}, "execution_count": 57, "outputs": []}, {"cell_type": "markdown", "source": "# MODEL DEFINITION", "metadata": {}}, {"cell_type": "code", "source": "input_layers = []\nfor m,m_name in enumerate(modalities):\n    input_layer = keras.Input(shape=X[m].shape[1:], name=f\"m{m+1}_input\")\n    input_layers.append(input_layer)\n\nm_output_layers = []\nfor m,m_name in enumerate(modalities):\n    output_layer = layers.Dense(1,activation='relu',\n                                kernel_regularizer=regularizers.l1(l1=L1_REGULARIZATION),\n                                name=f\"m{m+1}_output\")(input_layers[m])\n    m_output_layers.append(output_layer)\n# concatenation layer\nconcatenation = layers.concatenate(m_output_layers,name='concatenated_modalitites')\n# logisitc regression layer\nprediction = layers.Dense(1, name=\"output_layer\")(concatenation)\n\nmodel = keras.Model(\n    inputs=input_layers,\n    outputs=[prediction],\n)", "metadata": {"trusted": true}, "execution_count": 58, "outputs": []}, {"cell_type": "code", "source": "model.summary()", "metadata": {"trusted": true}, "execution_count": 59, "outputs": [{"name": "stdout", "text": "Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nm1_input (InputLayer)           [(None, 31)]         0                                            \n__________________________________________________________________________________________________\nm2_input (InputLayer)           [(None, 2349)]       0                                            \n__________________________________________________________________________________________________\nm3_input (InputLayer)           [(None, 2177)]       0                                            \n__________________________________________________________________________________________________\nm4_input (InputLayer)           [(None, 34)]         0                                            \n__________________________________________________________________________________________________\nm5_input (InputLayer)           [(None, 29)]         0                                            \n__________________________________________________________________________________________________\nm6_input (InputLayer)           [(None, 38892)]      0                                            \n__________________________________________________________________________________________________\nm7_input (InputLayer)           [(None, 55531)]      0                                            \n__________________________________________________________________________________________________\nm8_input (InputLayer)           [(None, 16098)]      0                                            \n__________________________________________________________________________________________________\nm9_input (InputLayer)           [(None, 99)]         0                                            \n__________________________________________________________________________________________________\nm10_input (InputLayer)          [(None, 227)]        0                                            \n__________________________________________________________________________________________________\nm1_output (Dense)               (None, 1)            32          m1_input[0][0]                   \n__________________________________________________________________________________________________\nm2_output (Dense)               (None, 1)            2350        m2_input[0][0]                   \n__________________________________________________________________________________________________\nm3_output (Dense)               (None, 1)            2178        m3_input[0][0]                   \n__________________________________________________________________________________________________\nm4_output (Dense)               (None, 1)            35          m4_input[0][0]                   \n__________________________________________________________________________________________________\nm5_output (Dense)               (None, 1)            30          m5_input[0][0]                   \n__________________________________________________________________________________________________\nm6_output (Dense)               (None, 1)            38893       m6_input[0][0]                   \n__________________________________________________________________________________________________\nm7_output (Dense)               (None, 1)            55532       m7_input[0][0]                   \n__________________________________________________________________________________________________\nm8_output (Dense)               (None, 1)            16099       m8_input[0][0]                   \n__________________________________________________________________________________________________\nm9_output (Dense)               (None, 1)            100         m9_input[0][0]                   \n__________________________________________________________________________________________________\nm10_output (Dense)              (None, 1)            228         m10_input[0][0]                  \n__________________________________________________________________________________________________\nconcatenated_modalitites (Conca (None, 10)           0           m1_output[0][0]                  \n                                                                 m2_output[0][0]                  \n                                                                 m3_output[0][0]                  \n                                                                 m4_output[0][0]                  \n                                                                 m5_output[0][0]                  \n                                                                 m6_output[0][0]                  \n                                                                 m7_output[0][0]                  \n                                                                 m8_output[0][0]                  \n                                                                 m9_output[0][0]                  \n                                                                 m10_output[0][0]                 \n__________________________________________________________________________________________________\noutput_layer (Dense)            (None, 1)            11          concatenated_modalitites[0][0]   \n==================================================================================================\nTotal params: 115,488\nTrainable params: 115,488\nNon-trainable params: 0\n__________________________________________________________________________________________________\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "# MODEL COMPILATION", "metadata": {}}, {"cell_type": "code", "source": "# model compilation\nmodel.compile(optimizer='Adam',\n              loss='binary_crossentropy',\n              metrics = ['accuracy'])", "metadata": {"id": "116-lAYQbp1y", "trusted": true}, "execution_count": 60, "outputs": []}, {"cell_type": "markdown", "source": "# MODEL TRAINING", "metadata": {}}, {"cell_type": "code", "source": "# train model\nhistory = model.fit(X,Y,epochs=EPOCHS,validation_split=VALIDATION_SPLIT, batch_size=BATCH_SIZE, shuffle=True,verbose=2)", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "KPlurteddSXY", "outputId": "2d85a28d-95c4-4ee6-d180-43d44b050d41", "trusted": true}, "execution_count": 61, "outputs": [{"name": "stdout", "text": "Epoch 1/100\n18/18 - 1s - loss: 194.7795 - accuracy: 0.5556 - val_loss: 103.5495 - val_accuracy: 0.0000e+00\nEpoch 2/100\n18/18 - 0s - loss: 75.7724 - accuracy: 0.5556 - val_loss: 73.8611 - val_accuracy: 0.0000e+00\nEpoch 3/100\n18/18 - 0s - loss: 43.1094 - accuracy: 0.4444 - val_loss: 32.3451 - val_accuracy: 0.0000e+00\nEpoch 4/100\n18/18 - 0s - loss: 29.5418 - accuracy: 0.6111 - val_loss: 28.3232 - val_accuracy: 0.0000e+00\nEpoch 5/100\n18/18 - 0s - loss: 44.4831 - accuracy: 0.6111 - val_loss: 41.0271 - val_accuracy: 1.0000\nEpoch 6/100\n18/18 - 0s - loss: 41.7812 - accuracy: 0.7222 - val_loss: 31.0159 - val_accuracy: 1.0000\nEpoch 7/100\n18/18 - 0s - loss: 29.5417 - accuracy: 0.6667 - val_loss: 21.9514 - val_accuracy: 1.0000\nEpoch 8/100\n18/18 - 0s - loss: 22.5118 - accuracy: 0.6111 - val_loss: 21.7708 - val_accuracy: 0.0000e+00\nEpoch 9/100\n18/18 - 0s - loss: 40.6814 - accuracy: 0.6111 - val_loss: 55.2251 - val_accuracy: 1.0000\nEpoch 10/100\n18/18 - 0s - loss: 47.8604 - accuracy: 0.6111 - val_loss: 27.4188 - val_accuracy: 1.0000\nEpoch 11/100\n18/18 - 0s - loss: 27.9608 - accuracy: 0.6667 - val_loss: 29.4620 - val_accuracy: 1.0000\nEpoch 12/100\n18/18 - 0s - loss: 36.5017 - accuracy: 0.8333 - val_loss: 77.1605 - val_accuracy: 0.0000e+00\nEpoch 13/100\n18/18 - 0s - loss: 53.0957 - accuracy: 0.6111 - val_loss: 68.6099 - val_accuracy: 0.0000e+00\nEpoch 14/100\n18/18 - 0s - loss: 62.3261 - accuracy: 0.6111 - val_loss: 74.3979 - val_accuracy: 0.0000e+00\nEpoch 15/100\n18/18 - 0s - loss: 73.8482 - accuracy: 0.6111 - val_loss: 141.2858 - val_accuracy: 0.0000e+00\nEpoch 16/100\n18/18 - 0s - loss: 122.2203 - accuracy: 0.6111 - val_loss: 100.8211 - val_accuracy: 0.0000e+00\nEpoch 17/100\n18/18 - 0s - loss: 63.3602 - accuracy: 0.6667 - val_loss: 44.9643 - val_accuracy: 0.0000e+00\nEpoch 18/100\n18/18 - 0s - loss: 32.4155 - accuracy: 0.7222 - val_loss: 28.4231 - val_accuracy: 0.0000e+00\nEpoch 19/100\n18/18 - 0s - loss: 128.3853 - accuracy: 0.5556 - val_loss: 209.3926 - val_accuracy: 0.0000e+00\nEpoch 20/100\n18/18 - 0s - loss: 187.4312 - accuracy: 0.6111 - val_loss: 168.4927 - val_accuracy: 0.0000e+00\nEpoch 21/100\n18/18 - 0s - loss: 124.5190 - accuracy: 0.6111 - val_loss: 97.3292 - val_accuracy: 0.0000e+00\nEpoch 22/100\n18/18 - 0s - loss: 66.6033 - accuracy: 0.6111 - val_loss: 56.8994 - val_accuracy: 0.0000e+00\nEpoch 23/100\n18/18 - 0s - loss: 36.2316 - accuracy: 0.6667 - val_loss: 31.6880 - val_accuracy: 0.0000e+00\nEpoch 24/100\n18/18 - 0s - loss: 29.1235 - accuracy: 0.6667 - val_loss: 46.2076 - val_accuracy: 0.0000e+00\nEpoch 25/100\n18/18 - 0s - loss: 41.5720 - accuracy: 0.6667 - val_loss: 69.3781 - val_accuracy: 0.0000e+00\nEpoch 26/100\n18/18 - 0s - loss: 46.9961 - accuracy: 0.6111 - val_loss: 103.2558 - val_accuracy: 0.0000e+00\nEpoch 27/100\n18/18 - 0s - loss: 194.8805 - accuracy: 0.6667 - val_loss: 254.8507 - val_accuracy: 0.0000e+00\nEpoch 28/100\n18/18 - 0s - loss: 237.6778 - accuracy: 0.6667 - val_loss: 229.9480 - val_accuracy: 0.0000e+00\nEpoch 29/100\n18/18 - 0s - loss: 195.7781 - accuracy: 0.6667 - val_loss: 177.6829 - val_accuracy: 0.0000e+00\nEpoch 30/100\n18/18 - 0s - loss: 143.4263 - accuracy: 0.6111 - val_loss: 126.3747 - val_accuracy: 0.0000e+00\nEpoch 31/100\n18/18 - 0s - loss: 97.0668 - accuracy: 0.6111 - val_loss: 86.6426 - val_accuracy: 0.0000e+00\nEpoch 32/100\n18/18 - 0s - loss: 64.1430 - accuracy: 0.6111 - val_loss: 60.5586 - val_accuracy: 0.0000e+00\nEpoch 33/100\n18/18 - 0s - loss: 41.7172 - accuracy: 0.6667 - val_loss: 43.5931 - val_accuracy: 0.0000e+00\nEpoch 34/100\n18/18 - 0s - loss: 27.1773 - accuracy: 0.6667 - val_loss: 38.1808 - val_accuracy: 0.0000e+00\nEpoch 35/100\n18/18 - 0s - loss: 26.7141 - accuracy: 0.7222 - val_loss: 32.2738 - val_accuracy: 0.0000e+00\nEpoch 36/100\n18/18 - 0s - loss: 17.0777 - accuracy: 0.7222 - val_loss: 17.4203 - val_accuracy: 0.0000e+00\nEpoch 37/100\n18/18 - 0s - loss: 21.3423 - accuracy: 0.7778 - val_loss: 18.6681 - val_accuracy: 0.0000e+00\nEpoch 38/100\n18/18 - 0s - loss: 16.2609 - accuracy: 0.7222 - val_loss: 14.5875 - val_accuracy: 1.0000\nEpoch 39/100\n18/18 - 0s - loss: 13.1970 - accuracy: 0.6667 - val_loss: 12.4674 - val_accuracy: 1.0000\nEpoch 40/100\n18/18 - 0s - loss: 14.5848 - accuracy: 0.7778 - val_loss: 11.0959 - val_accuracy: 0.0000e+00\nEpoch 41/100\n18/18 - 0s - loss: 11.4827 - accuracy: 0.5556 - val_loss: 23.1302 - val_accuracy: 0.0000e+00\nEpoch 42/100\n18/18 - 0s - loss: 40.7660 - accuracy: 0.5556 - val_loss: 52.2918 - val_accuracy: 0.0000e+00\nEpoch 43/100\n18/18 - 0s - loss: 35.8150 - accuracy: 0.5556 - val_loss: 24.2970 - val_accuracy: 1.0000\nEpoch 44/100\n18/18 - 0s - loss: 24.7780 - accuracy: 0.5556 - val_loss: 17.6913 - val_accuracy: 0.0000e+00\nEpoch 45/100\n18/18 - 0s - loss: 19.8966 - accuracy: 0.6111 - val_loss: 16.3715 - val_accuracy: 1.0000\nEpoch 46/100\n18/18 - 0s - loss: 19.8285 - accuracy: 0.5556 - val_loss: 12.7843 - val_accuracy: 1.0000\nEpoch 47/100\n18/18 - 0s - loss: 16.4011 - accuracy: 0.5556 - val_loss: 28.4932 - val_accuracy: 0.0000e+00\nEpoch 48/100\n18/18 - 0s - loss: 21.0082 - accuracy: 0.5556 - val_loss: 28.1381 - val_accuracy: 0.0000e+00\nEpoch 49/100\n18/18 - 0s - loss: 20.6539 - accuracy: 0.5556 - val_loss: 33.2866 - val_accuracy: 0.0000e+00\nEpoch 50/100\n18/18 - 0s - loss: 21.2586 - accuracy: 0.5000 - val_loss: 15.2373 - val_accuracy: 1.0000\nEpoch 51/100\n18/18 - 0s - loss: 19.6454 - accuracy: 0.5556 - val_loss: 11.7489 - val_accuracy: 1.0000\nEpoch 52/100\n18/18 - 0s - loss: 20.2201 - accuracy: 0.5556 - val_loss: 29.9742 - val_accuracy: 0.0000e+00\nEpoch 53/100\n18/18 - 0s - loss: 18.7752 - accuracy: 0.5556 - val_loss: 14.1915 - val_accuracy: 1.0000\nEpoch 54/100\n18/18 - 0s - loss: 16.9269 - accuracy: 0.6667 - val_loss: 29.7005 - val_accuracy: 0.0000e+00\nEpoch 55/100\n18/18 - 0s - loss: 20.5341 - accuracy: 0.6111 - val_loss: 28.2488 - val_accuracy: 0.0000e+00\nEpoch 56/100\n18/18 - 0s - loss: 17.6905 - accuracy: 0.6667 - val_loss: 31.4755 - val_accuracy: 0.0000e+00\nEpoch 57/100\n18/18 - 0s - loss: 20.7421 - accuracy: 0.5000 - val_loss: 32.1306 - val_accuracy: 0.0000e+00\nEpoch 58/100\n18/18 - 0s - loss: 25.7042 - accuracy: 0.3333 - val_loss: 22.1147 - val_accuracy: 1.0000\nEpoch 59/100\n18/18 - 0s - loss: 32.0458 - accuracy: 0.5000 - val_loss: 30.9515 - val_accuracy: 1.0000\nEpoch 60/100\n18/18 - 0s - loss: 30.3413 - accuracy: 0.7222 - val_loss: 21.1163 - val_accuracy: 1.0000\nEpoch 61/100\n18/18 - 0s - loss: 38.5001 - accuracy: 0.6111 - val_loss: 66.3879 - val_accuracy: 1.0000\nEpoch 62/100\n18/18 - 0s - loss: 77.2829 - accuracy: 0.5000 - val_loss: 81.8844 - val_accuracy: 1.0000\nEpoch 63/100\n18/18 - 0s - loss: 82.8557 - accuracy: 0.5000 - val_loss: 80.9734 - val_accuracy: 1.0000\nEpoch 64/100\n18/18 - 0s - loss: 80.9385 - accuracy: 0.5000 - val_loss: 78.6967 - val_accuracy: 1.0000\nEpoch 65/100\n18/18 - 0s - loss: 78.7794 - accuracy: 0.4444 - val_loss: 77.0465 - val_accuracy: 1.0000\nEpoch 66/100\n18/18 - 0s - loss: 74.5852 - accuracy: 0.5556 - val_loss: 70.9131 - val_accuracy: 1.0000\nEpoch 67/100\n18/18 - 0s - loss: 69.8439 - accuracy: 0.4444 - val_loss: 67.0192 - val_accuracy: 1.0000\nEpoch 68/100\n18/18 - 0s - loss: 65.9087 - accuracy: 0.5000 - val_loss: 62.7473 - val_accuracy: 1.0000\nEpoch 69/100\n18/18 - 0s - loss: 62.3098 - accuracy: 0.5000 - val_loss: 60.7888 - val_accuracy: 1.0000\nEpoch 70/100\n18/18 - 0s - loss: 59.4330 - accuracy: 0.4444 - val_loss: 56.8000 - val_accuracy: 1.0000\nEpoch 71/100\n18/18 - 0s - loss: 56.0563 - accuracy: 0.4444 - val_loss: 53.4649 - val_accuracy: 1.0000\nEpoch 72/100\n18/18 - 0s - loss: 51.4710 - accuracy: 0.4444 - val_loss: 49.2771 - val_accuracy: 1.0000\nEpoch 73/100\n18/18 - 0s - loss: 48.1694 - accuracy: 0.5000 - val_loss: 45.8570 - val_accuracy: 1.0000\nEpoch 74/100\n18/18 - 0s - loss: 44.0650 - accuracy: 0.5000 - val_loss: 42.6988 - val_accuracy: 1.0000\nEpoch 75/100\n18/18 - 0s - loss: 39.7738 - accuracy: 0.5000 - val_loss: 36.7133 - val_accuracy: 1.0000\nEpoch 76/100\n18/18 - 0s - loss: 36.2456 - accuracy: 0.4444 - val_loss: 32.8493 - val_accuracy: 1.0000\nEpoch 77/100\n18/18 - 0s - loss: 34.0004 - accuracy: 0.4444 - val_loss: 30.8800 - val_accuracy: 1.0000\nEpoch 78/100\n18/18 - 0s - loss: 33.0119 - accuracy: 0.4444 - val_loss: 29.6048 - val_accuracy: 1.0000\nEpoch 79/100\n18/18 - 0s - loss: 32.6800 - accuracy: 0.4444 - val_loss: 28.1576 - val_accuracy: 1.0000\nEpoch 80/100\n18/18 - 0s - loss: 40.6933 - accuracy: 0.4444 - val_loss: 41.1829 - val_accuracy: 1.0000\nEpoch 81/100\n18/18 - 0s - loss: 38.8012 - accuracy: 0.5556 - val_loss: 33.6318 - val_accuracy: 1.0000\nEpoch 82/100\n18/18 - 0s - loss: 34.9586 - accuracy: 0.6111 - val_loss: 28.4038 - val_accuracy: 1.0000\nEpoch 83/100\n18/18 - 0s - loss: 32.2183 - accuracy: 0.5556 - val_loss: 28.0005 - val_accuracy: 1.0000\nEpoch 84/100\n18/18 - 0s - loss: 33.6251 - accuracy: 0.6667 - val_loss: 27.7674 - val_accuracy: 1.0000\nEpoch 85/100\n18/18 - 0s - loss: 32.7726 - accuracy: 0.6667 - val_loss: 27.0362 - val_accuracy: 1.0000\nEpoch 86/100\n18/18 - 0s - loss: 32.7082 - accuracy: 0.6111 - val_loss: 26.9278 - val_accuracy: 1.0000\nEpoch 87/100\n18/18 - 0s - loss: 33.2517 - accuracy: 0.6111 - val_loss: 32.9369 - val_accuracy: 1.0000\nEpoch 88/100\n18/18 - 0s - loss: 36.0034 - accuracy: 0.6667 - val_loss: 28.7643 - val_accuracy: 1.0000\nEpoch 89/100\n18/18 - 0s - loss: 32.0506 - accuracy: 0.7222 - val_loss: 26.4312 - val_accuracy: 1.0000\nEpoch 90/100\n18/18 - 0s - loss: 30.0226 - accuracy: 0.6667 - val_loss: 24.8246 - val_accuracy: 1.0000\nEpoch 91/100\n18/18 - 0s - loss: 36.5527 - accuracy: 0.6667 - val_loss: 39.0329 - val_accuracy: 1.0000\nEpoch 92/100\n18/18 - 0s - loss: 42.7418 - accuracy: 0.7778 - val_loss: 38.3359 - val_accuracy: 1.0000\nEpoch 93/100\n18/18 - 0s - loss: 40.2449 - accuracy: 0.7778 - val_loss: 34.6617 - val_accuracy: 1.0000\nEpoch 94/100\n18/18 - 0s - loss: 36.2964 - accuracy: 0.7778 - val_loss: 31.1845 - val_accuracy: 1.0000\nEpoch 95/100\n18/18 - 0s - loss: 32.6706 - accuracy: 0.7778 - val_loss: 27.0331 - val_accuracy: 1.0000\nEpoch 96/100\n18/18 - 0s - loss: 28.6655 - accuracy: 0.7778 - val_loss: 23.1360 - val_accuracy: 1.0000\nEpoch 97/100\n18/18 - 0s - loss: 25.2746 - accuracy: 0.5556 - val_loss: 30.4366 - val_accuracy: 1.0000\nEpoch 98/100\n18/18 - 0s - loss: 31.3212 - accuracy: 0.8333 - val_loss: 39.4298 - val_accuracy: 1.0000\nEpoch 99/100\n18/18 - 0s - loss: 94.5160 - accuracy: 0.7778 - val_loss: 95.8261 - val_accuracy: 1.0000\nEpoch 100/100\n18/18 - 0s - loss: 69.9081 - accuracy: 0.7222 - val_loss: 44.2372 - val_accuracy: 1.0000\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "# Feature ranking", "metadata": {}}, {"cell_type": "code", "source": "#feature rakings\noutput_dfs = {}\n\nmod_w = model.get_layer('output_layer').get_weights()[0].flatten()\nfor m,m_name in enumerate(modalities):\n    features_w = model.get_layer(f'm{m+1}_output').get_weights()[0].flatten()\n    tot_w = features_w*mod_w[m]\n    mod_order = tot_w.argsort()[::-1] # to rank from larger to smaller\n    mod_ranks = mod_order.argsort()\n    \n    df = pd.DataFrame(columns=['Feature_ID','Rank','Score'])\n    df['Feature_ID'] = dataframes[m_name].columns\n    df['Rank'] = mod_ranks\n    df['Score'] = tot_w\n    \n    output_dfs[m_name] = df.sort_values(by=['Rank'])\n    \n# modality weights\nmod_df = pd.DataFrame(columns=['Modality','Weight'])\nmod_df['Modality'] = modalities\nmod_df['Weight'] = mod_w\n    ", "metadata": {"trusted": true}, "execution_count": 66, "outputs": []}, {"cell_type": "markdown", "source": "# SAVE OUTPUT", "metadata": {}}, {"cell_type": "code", "source": "# make model_output dir\nPath(output_path).mkdir(parents=True, exist_ok=True)\n\n# save_dataframes\nfor key in output_dfs.keys():\n    output_dfs[key].to_csv(output_path +'/'+key,sep='\\t',index=False,header=output_dfs[key].columns)\n\n# save modality weigths\nmod_df.to_csv(output_path +'/modality_weights',sep='\\t',index=False,header=mod_df.columns)\n\n# save trained model\nmodel_path = output_path+'/'+'model'\nPath(model_path).mkdir(parents=True, exist_ok=True)\nmodel.save(model_path)\n\n# save training history\nwith open(model_path+'/trainHistoryDict', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)\n", "metadata": {"trusted": true}, "execution_count": 71, "outputs": [{"name": "stdout", "text": "INFO:tensorflow:Assets written to: model_output/model/assets\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "# upload output to DNAnexus\n!dx upload -r model_output", "metadata": {"trusted": true}, "execution_count": 48, "outputs": [{"name": "stdout", "text": "[===========================================================>] Uploaded 1,247 of 1,247 bytes (100%) model_output/HERV_K_Insertions.txt\n[===========================================================>] Uploaded 23,990 of 23,990 bytes (100%) model_output/SV_VCFs.INS.gene_scores_matrix.tsv.gz\n[===========================================================>] Uploaded 24,203 of 24,203 bytes (100%) model_output/SV_VCFs.DEL.gene_scores_matrix.tsv.gz\n[===========================================================>] Uploaded 435 of 435 bytes (100%) model_output/SV_VCFs.INV.gene_scores_matrix.tsv.gz\n[===========================================================>] Uploaded 418 of 418 bytes (100%) model_output/SV_VCFs.DUP-TANDEM.gene_scores_matrix.tsv.gz\n[===========================================================>] Uploaded 444,624 of 444,624 bytes (100%) model_output/SNP_VCFs.genotype_matrix.tsv.gz\n[===========================================================>] Uploaded 589,517 of 589,517 bytes (100%) model_output/SV_VCFs.DEL.genotype_matrix.tsv.gz\n[===========================================================>] Uploaded 165,547 of 165,547 bytes (100%) model_output/SV_VCFs.INS.genotype_matrix.tsv.gz\n[===========================================================>] Uploaded 1,246 of 1,246 bytes (100%) model_output/SV_VCFs.DUP-TANDEM.genotype_matrix.tsv.gz\n[===========================================================>] Uploaded 2,822 of 2,822 bytes (100%) model_output/SV_VCFs.INV.genotype_matrix.tsv.gz\n[===========================================================>] Uploaded 4,940 of 4,940 bytes (100%) model_output/model/variables/variables.index\n[===========================================================>] Uploaded 1,400,321 of 1,400,321 bytes (100%) model_output/model/variables/variables.data-00000-of-00001\n[===========================================================>] Uploaded 42,606 of 42,606 bytes (100%) model_output/model/keras_metadata.pb\n[===========================================================>] Uploaded 3,688 of 3,688 bytes (100%) model_output/model/trainHistoryDict\n[===========================================================>] Uploaded 404,986 of 404,986 bytes (100%) model_output/model/saved_model.pb\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}